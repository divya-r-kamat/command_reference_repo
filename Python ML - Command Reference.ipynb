{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Typical ML Problems\n",
    "1. identification of the problem\n",
    "2. Split the data into Training and Validation set\n",
    "3.  identification of different variables in the data\n",
    "4. Separate out the numerical variables first. These variables don’t need any kind of processing and thus we can start applying normalization and machine learning models to these variables\n",
    "5. There are two ways in which we can handle categorical data:\n",
    "\t1. Convert the categorical data to labels using LabelEncoder\n",
    "\t2. Convert the labels to binary variables (one-hot encoding)\n",
    "6. Stack the features together\n",
    "7. start applying machine learning models. \n",
    "\tAt this stage only models you should go for should be ensemble tree based models. These models include:\n",
    "\t\tRandomForestClassifier\n",
    "\t\tRandomForestRegressor\n",
    "\t\tExtraTreesClassifier\n",
    "\t\tExtraTreesRegressor\n",
    "\t\tXGBClassifier\n",
    "\t\tXGBRegressor\n",
    "\n",
    "\t To use linear models, one can use Normalizer or StandardScaler from scikit-learn.\n",
    "\t Normalization methods work only on dense features and don’t give very good results if applied on sparse features. \t Yes, one can apply StandardScaler on sparse matrices without using the mean (parameter: with_mean=False).\n",
    "\n",
    "8. If the above steps give a “good” model, we can go for optimization of hyperparameters \n",
    "\n",
    "else decomposition methods to improve the model\n",
    "\n",
    "    PCA\n",
    "    LDA\n",
    "    QDA\n",
    "    SVD\n",
    "\n",
    "    PCA - for images start with 10-15 componenets and increase this number as long as the quality of result improves substantially\n",
    "    For other type of data, we select 50-60 components initially (we tend to avoid PCA as long as we can deal with the numerical data as it is)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All necessary Import Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# calculate accuracy measures and confusion matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read file without column names\n",
    "columns = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin',\n",
    "           'BMI','DiabetesPedigreeFunction','Age','Outcome']\n",
    "X = pd.read_csv(r\"C:\\Users\\divyakamat\\PG_AI_ML\\python\\project\\module_3\\pima-indians-diabetes.data\", names=columns)\n",
    "y = X.pop(\"Outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating Independent and Dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'Attrition'\n",
    "X = df.loc[:, df.columns!=target]\n",
    "y = df.loc[:, df.columns==target]\n",
    "\n",
    "\n",
    "y = np.where(df['Class']== 2, 1, 0)\n",
    "y = np.where(df['Attrition']=='Yes', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total missing values for each feature\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replace Missing Values\n",
    "\n",
    "# Replace missing values with a number\n",
    "df['ST_NUM'].fillna(125, inplace=True)\n",
    "\n",
    "# Location based replacement\n",
    "df.loc[2,'ST_NUM'] = 125\n",
    "\n",
    "# Replace using median \n",
    "median = df['NUM_BEDROOMS'].median()\n",
    "df['NUM_BEDROOMS'].fillna(median, inplace=True\n",
    "\n",
    "df['Bare Nuclei'] = df['Bare Nuclei'].replace({0: median})\n",
    "                          \n",
    "          \n",
    "#Replace ? with Nan\n",
    "df.replace({'?': np.nan})\n",
    "\n",
    "df = df.replace({'?': np.nan})\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace zero with mean and median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Pres'] = df['Pres'].replace({0: df['Pres'].mean()})\n",
    "df['mass'] = df['mass'].replace({0: df['mass'].median()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 32',\"id\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "data.diagnosis = [1 if x == \"M\" else 0 for x in data.diagnosis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dataframe copy\n",
    "train_data = train_df.copy()\n",
    "\n",
    "#Use median to fill NaNs\n",
    "train_data[\"Age\"].fillna(train_df[\"Age\"].median(skipna=True), inplace=True)\n",
    "\n",
    "#Use mode or maximum value to fill nan in categorical features\n",
    "train_data[\"Embarked\"].fillna(train_df['Embarked'].value_counts().idxmax(), inplace=True)\n",
    "\n",
    "#Drop a column\n",
    "train_data.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pd.to_datetime(df['date'])\n",
    "\n",
    "for feature in credit_df.columns: # Loop through all columns in the dataframe\n",
    "    if credit_df[feature].dtype == 'object': # Only apply for columns with categorical strings\n",
    "        credit_df[feature] = pd.Categorical(credit_df[feature]).codes # Replace strings with an integer\n",
    "        \n",
    "        \n",
    "df[\"Bare Nuclei\"]=df[\"Bare Nuclei\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def strip_character(dataCol):\n",
    "    r = re.compile(r'[^a-zA-Z !@#$%&*_+-=|\\:\";<>,./()[\\]{}\\']')\n",
    "    return r.sub('', dataCol)\n",
    "\n",
    "df[resultCol] = df[dataCol].apply(strip_character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical column details in tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basic_details(df):\n",
    "    b = pd.DataFrame()\n",
    "    b['Missing value'] = df.isnull().sum()\n",
    "    b['N unique value'] = df.nunique()\n",
    "    b['dtype'] = df.dtypes\n",
    "    return b\n",
    "basic_details(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset with numerical features\n",
    "numeric_variables= list(X.dtypes[X.dtypes != \"object\"].index)\n",
    "X[numeric_variables].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List Categorical features\n",
    "def describe_categorical(X):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X[X.columns[X.dtypes == \"object\"]].describe().to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_feature_columns = list(set(credit_df.columns) - set(credit_df._get_numeric_data().columns))\n",
    "categorical_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [a for a in categorical_feature_columns if not a.startswith('default')]:\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"Value counts for :\",i)\n",
    "    print(\"----------------------------------------\")\n",
    "    print(credit_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.dtypes[(df.dtypes != \"object\")].index.values].hist(figsize=[11,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [a for a in categorical_feature_columns if not a.startswith('default')]:\n",
    "        pd.crosstab(credit_df[i],credit_df.default).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% normalization\n",
    "x = (x_data -np.min(x_data))/(np.max(x_data)-np.min(x_data)).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to plot graph before and after missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "ax = train_df[\"Age\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "train_df[\"Age\"].plot(kind='density', color='teal')\n",
    "ax = train_data[\"Age\"].hist(bins=15, density=True, stacked=True, color='orange', alpha=0.5)\n",
    "train_data[\"Age\"].plot(kind='density', color='orange')\n",
    "ax.legend(['Raw Age', 'Adjusted Age'])\n",
    "ax.set(xlabel='Age')\n",
    "plt.xlim(-10,85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.barplot('Sex', 'Survived', data=train_df, color=\"aquamarine\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical = [\n",
    "  'MSZoning', 'LotShape', 'Neighborhood', 'CentralAir', 'SaleCondition', 'MoSold', 'YrSold'\n",
    "]\n",
    "fig, ax = plt.subplots(2, 4, figsize=(20, 10))\n",
    "for variable, subplot in zip(categorical, ax.flatten()):\n",
    "    sns.countplot(housing[variable], ax=subplot)\n",
    "    for label in subplot.get_xticklabels():\n",
    "        label.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(15, 10))\n",
    "for var, subplot in zip(categorical, ax.flatten()):\n",
    "    sns.boxplot(x=var, y='SalePrice', data=housing, ax=subplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [a for a in categorical_feature_columns if not a.startswith('default')]:\n",
    "    table=pd.crosstab(credit_df[i],credit_df.default)\n",
    "    table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Print Max rows\n",
    "def printall(X,max_rows=10):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(X.to_html(max_rows=max_rows)))\n",
    "printall(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_cabin(X):\n",
    "    try:\n",
    "        return x[0]\n",
    "    except TypeError:\n",
    "        return \"None\"\n",
    "    \n",
    "X[\"Cabin\"] = X.Cabin.apply(clean_cabin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of feature against target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "ax = sns.kdeplot(df[\"mass\"][df[\"class\"] == 1], color=\"darkturquoise\", shade=True)\n",
    "sns.kdeplot(df[\"mass\"][df[\"class\"] == 0], color=\"lightcoral\", shade=True)\n",
    "plt.legend(['mass', 'class'])\n",
    "plt.title('Density Plot of mass for diabetic and non diabetic Population')\n",
    "ax.set(xlabel='Age')\n",
    "plt.xlim(-10,85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine outliers in dataset\n",
    "The extreme observations in data set which resembles completely different behavoir from the rest of data point are called outliers. The outliers present in numeric feature are replaced by 1%/99% of feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def outlier(df,columns):\n",
    "    for i in columns:\n",
    "        quartile_1,quartile_3 = np.percentile(df[i],[25,75])\n",
    "        quartile_f,quartile_l = np.percentile(df[i],[1,99])\n",
    "        IQR = quartile_3-quartile_1\n",
    "        lower_bound = quartile_1 - (1.5*IQR)\n",
    "        upper_bound = quartile_3 + (1.5*IQR)\n",
    "        print(i,lower_bound,upper_bound,quartile_f,quartile_l)\n",
    "                \n",
    "        df[i].loc[df[i] < lower_bound] = quartile_f\n",
    "        df[i].loc[df[i] > upper_bound] = quartile_l\n",
    "        \n",
    "outlier(train,num_col)\n",
    "outlier(test,num_col) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Splitting\n",
    "\n",
    "The splitting of data into training and validation sets “must” be done according to labels. In case of any kind of classification problem, use stratified splitting. In python, you can do this using scikit-learn very easily.\n",
    "\n",
    "eval_size or the size of the validation set as 10% of the full data in the examples, but one can choose this value according to the size of the data they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "eval_size = 0.10\n",
    "kf = StratifiedKFold(y,round (1./eval_size) )\n",
    "train_indices,valid_indices = next (iter(kf))\n",
    "X_train, y_train = X[train_indices], y[train_indices]\n",
    "X_valid, y_valid = X[valid_indices], y[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "eval_size = 0.10\n",
    "kf = KFold(len(y),round (1./eval_size) )\n",
    "train_indices,valid_indices = next (iter(kf))\n",
    "X_train, y_train = X[train_indices], y[train_indices]\n",
    "X_valid, y_valid = X[valid_indices], y[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lbl_enc = LabelEncoder()\n",
    "lbl_enc.fit(X_train[categorical_features])\n",
    "Xtrain_cat = lbl_enc.transform(X_train[categorical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(X_train[categorical_features])\n",
    "Xtrain_cat = ohe.transform(X_train[categorical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding using pd.get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#create categorical variables and drop some variables\n",
    "training=pd.get_dummies(train_data, columns=[\"Pclass\",\"Embarked\",\"Sex\"])\n",
    "\n",
    "#Drop the actual columns \n",
    "training.drop('Sex_female', axis=1, inplace=True)\n",
    "training.drop('PassengerId', axis=1, inplace=True)\n",
    "training.drop('Name', axis=1, inplace=True)\n",
    "training.drop('Ticket', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine text variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_data = list(X_train.apply(lambda s: '%s %s' %(x['column_1'],x['column_2']),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##We can then use CountVectorizer or TfidfVectorizer on it\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "ctv = CountVectorizer()\n",
    "text_data_train = ctv.fit_transform(text_data_train)\n",
    "text_data_valid = ctv.fit_transform(text_data_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfv = TfidfVectorizer()\n",
    "text_data_train = tfv.fit_transform(text_data_train)\n",
    "text_data_valid = tfv.fit_transform(text_data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TfidfVectorizer performs better than the counts most of the time\n",
    "tfv = TfidfVectorizer(min_df=3, max_features=None, strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}'\n",
    "                     ngram_range=(1,2), use_idf=1,smooth_idf=1, sublinear_tf=1,\n",
    "                     stop_words = 'english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If you are applying these vectorizers only on the training set,\n",
    "#make sure to dump it to hard drive so that you can use it later on the validation set.\n",
    "\n",
    "import cPickle\n",
    "cPickle.dump(vectorizer, open('vectorizer.pkl','wb'),-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacker Module\n",
    "\n",
    "Stacker module is not a model stacker but a feature stacker. The different features after the processing steps described above can be combined using the stacker module.\n",
    "\n",
    "You can horizontally stack all the features before putting them through further processing by using numpy hstack or sparse hstack depending on whether you have dense or sparse features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "#in case of dense data\n",
    "#Stack arrays in sequence horizontally (column wise).\n",
    "X = np.hstack((x1,x2, ...))\n",
    "\n",
    "# in case data is sparse\n",
    "X = sparse.hstack((x1,x2, ...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition using PCA and SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_componenets = 12)\n",
    "pca.fit(xtrain)\n",
    "xtrain = pca.transform(xtrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For text data, after conversion of text to sparse matrix, go for Singular Value Decomposition (SVD). A variation of SVD called TruncatedSVD can be found in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_componenets = 12o)\n",
    "svd.fit(xtrain)\n",
    "xtrain = svd.transform(xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of SVD components that generally work for TF-IDF or counts are between 120-200. Any number above this might improve the performance but not substantially and comes at the cost of computing power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "There are multiple ways in which feature selection can be achieved. One of the most common way is greedy feature selection (forward or backward). In greedy feature selection we choose one feature, train a model and evaluate the performance of the model on a fixed evaluation metric. We keep adding and removing features one-by-one and record performance of the model at every step. We then select the features which have the best evaluation score. \n",
    "\n",
    "Other faster methods of feature selection include selecting best features from a model. We can either look at coefficients of a logit model or we can train a random forest to select best features and then use them later with other machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100, n_jobs = -1)\n",
    "clf.fit(X,y)\n",
    "X_Selected = clf.transform(X)\n",
    "\n",
    "#Remember to keep low number of estimators and minimal optimization of hyper parameters so that you don’t overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100,oob_score=True,random_state=42)\n",
    "model.fit(X,y)\n",
    "model.feature_importances_\n",
    "\n",
    "# feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "# feature_importances.plot(kind='barh',figsize=[7,6])\n",
    "\n",
    "print(pd.DataFrame(dt_model.feature_importances_, columns = [\"Imp\"], index = X_train.columns).sort_values(['Imp'],ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature selection can also be achieved using Gradient Boosting Machines. It is good if we use xgboost instead of the implementation of GBM in scikit-learn since xgboost is much faster and more scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "params = {}\n",
    "\n",
    "model = xgb.train(params,dtrain, num_boost_round=100)\n",
    "sorted(model.get_fscore().items(),key=lambda t: -t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do feature selection of sparse datasets using RandomForestClassifier / RandomForestRegressor and xgboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chisqaure Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare,chi2_contingency\n",
    "\n",
    "alpha=0.05\n",
    "for i in [a for a in categorical_feature_columns if not a.startswith('default')]:\n",
    "    print(\"ChiSquare test for: \",i)\n",
    "    print(\"----------------------------------------\")\n",
    "    table=pd.crosstab(credit_df[i],credit_df.default)\n",
    "    chi2,pval,dof,expected = chi2_contingency(table)\n",
    "    print(\"ChiSquare test statistic: \",chi2)\n",
    "    print(\"p-value: \",pval)\n",
    "    \n",
    "    \n",
    "    if pval < alpha:\n",
    "            result=\"\\n{0} is IMPORTANT for Prediction\".format(i)\n",
    "    else:\n",
    "            result=\"\\n{0} is NOT an important predictor. (Discard {0} from model)\".format(i)\n",
    "\n",
    "    print(result) \n",
    "    print(\"\\n===============================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination\n",
    "Given an external estimator that assigns weights to features, recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features.That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "cols = [\"Age\",\"Fare\",\"TravelAlone\",\"Pclass_1\",\"Pclass_2\",\"Embarked_C\",\"Embarked_S\",\"Sex_male\",\"IsMinor\"] \n",
    "X = final_train[cols]\n",
    "y = final_train['Survived']\n",
    "# Build a logreg and compute the feature importances\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 8 attributes\n",
    "rfe = RFE(model, 8)\n",
    "rfe = rfe.fit(X, y)\n",
    "# summarize the selection of the attributes\n",
    "print('Selected features: %s' % list(X.columns[rfe.support_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature ranking with recursive feature elimination and cross-validation\n",
    "RFECV performs RFE in a cross-validation loop to find the optimal number or the best number of features. Hereafter a recursive feature elimination applied on logistic regression with automatic tuning of the number of features selected with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "rfecv = RFECV(estimator=LogisticRegression(), step=1, cv=10, scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
    "print('Selected features: %s' % list(X.columns[rfecv.support_]))\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Selected_features = ['Age', 'TravelAlone', 'Pclass_1', 'Pclass_2', 'Embarked_C', \n",
    "                     'Embarked_S', 'Sex_male', 'IsMinor']\n",
    "X = final_train[Selected_features]\n",
    "\n",
    "plt.subplots(figsize=(8, 5))\n",
    "sns.heatmap(X.corr(), annot=True, cmap=\"RdYlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_learning_curves\n",
    "\n",
    "#plot learning curves\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "bagging1 = BaggingClassifier(base_estimator=clf1, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
    "\n",
    "plt.figure()\n",
    "plot_learning_curves(X_train, y_train, X_test, y_test, bagging1, print_model=False, style='ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model evaluation based on simple train/test split using train_test_split() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score \n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss\n",
    "\n",
    "# create X (features) and y (response)\n",
    "X = final_train[Selected_features]\n",
    "y = final_train['Survived']\n",
    "\n",
    "# use train/test split with different random_state values\n",
    "# we can change the random_state values that changes the accuracy scores\n",
    "# the scores change a lot, this is why testing scores is a high-variance estimate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "# check classification scores of logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
    "[fpr, tpr, thr] = roc_curve(y_test, y_pred_proba)\n",
    "print('Train/Test split results:')\n",
    "print(logreg.__class__.__name__+\" accuracy is %2.3f\" % accuracy_score(y_test, y_pred))\n",
    "print(logreg.__class__.__name__+\" log_loss is %2.3f\" % log_loss(y_test, y_pred_proba))\n",
    "print(logreg.__class__.__name__+\" auc is %2.3f\" % auc(fpr, tpr))\n",
    "\n",
    "idx = np.min(np.where(tpr > 0.95)) # index of the first threshold for which the sensibility > 0.95\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='coral', label='ROC curve (area = %0.3f)' % auc(fpr, tpr))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot([0,fpr[idx]], [tpr[idx],tpr[idx]], 'k--', color='blue')\n",
    "plt.plot([fpr[idx],fpr[idx]], [0,tpr[idx]], 'k--', color='blue')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (1 - specificity)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (recall)', fontsize=14)\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Using a threshold of %.3f \" % thr[idx] + \"guarantees a sensitivity of %.3f \" % tpr[idx] +  \n",
    "      \"and a specificity of %.3f\" % (1-fpr[idx]) + \n",
    "      \", i.e. a false positive rate of %.2f%%.\" % (np.array(fpr[idx])*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model evaluation based on K-fold cross-validation using cross_val_score() function¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10-fold cross-validation logistic regression\n",
    "logreg = LogisticRegression()\n",
    "# Use cross_val_score function\n",
    "# We are passing the entirety of X and y, not X_train or y_train, it takes care of splitting the data\n",
    "# cv=10 for 10 folds\n",
    "# scoring = {'accuracy', 'neg_log_loss', 'roc_auc'} for evaluation metric - althought they are many\n",
    "scores_accuracy = cross_val_score(logreg, X, y, cv=10, scoring='accuracy')\n",
    "scores_log_loss = cross_val_score(logreg, X, y, cv=10, scoring='neg_log_loss')\n",
    "scores_auc = cross_val_score(logreg, X, y, cv=10, scoring='roc_auc')\n",
    "print('K-fold cross-validation results:')\n",
    "print(logreg.__class__.__name__+\" average accuracy is %2.3f\" % scores_accuracy.mean())\n",
    "print(logreg.__class__.__name__+\" average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
    "print(logreg.__class__.__name__+\" average auc is %2.3f\" % scores_auc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model evaluation based on K-fold cross-validation using cross_validate() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring = {'accuracy': 'accuracy', 'log_loss': 'neg_log_loss', 'auc': 'roc_auc'}\n",
    "\n",
    "modelCV = LogisticRegression()\n",
    "\n",
    "results = cross_validate(modelCV, X, y, cv=10, scoring=list(scoring.values()), \n",
    "                         return_train_score=False)\n",
    "\n",
    "print('K-fold cross-validation results:')\n",
    "for sc in range(len(scoring)):\n",
    "    print(modelCV.__class__.__name__+\" average %s: %.3f (+/-%.3f)\" % (list(scoring.keys())[sc], -results['test_%s' % list(scoring.values())[sc]].mean()\n",
    "                               if list(scoring.values())[sc]=='neg_log_loss' \n",
    "                               else results['test_%s' % list(scoring.values())[sc]].mean(), \n",
    "                               results['test_%s' % list(scoring.values())[sc]].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. GridSearchCV evaluating using multiple scorers simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = final_train[Selected_features]\n",
    "\n",
    "param_grid = {'C': np.arange(1e-05, 3, 0.1)}\n",
    "scoring = {'Accuracy': 'accuracy', 'AUC': 'roc_auc', 'Log_loss': 'neg_log_loss'}\n",
    "\n",
    "gs = GridSearchCV(LogisticRegression(), return_train_score=True,\n",
    "                  param_grid=param_grid, scoring=scoring, cv=10, refit='Accuracy')\n",
    "\n",
    "gs.fit(X, y)\n",
    "results = gs.cv_results_\n",
    "\n",
    "print('='*20)\n",
    "print(\"best params: \" + str(gs.best_estimator_))\n",
    "print(\"best params: \" + str(gs.best_params_))\n",
    "print('best score:', gs.best_score_)\n",
    "print('='*20)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\",fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Inverse of regularization strength: C\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_xlim(0, param_grid['C'].max()) \n",
    "ax.set_ylim(0.35, 0.95)\n",
    "\n",
    "# Get the regular numpy array from the MaskedArray\n",
    "X_axis = np.array(results['param_C'].data, dtype=float)\n",
    "\n",
    "for scorer, color in zip(list(scoring.keys()), ['g', 'k', 'b']): \n",
    "    for sample, style in (('train', '--'), ('test', '-')):\n",
    "        sample_score_mean = -results['mean_%s_%s' % (sample, scorer)] if scoring[scorer]=='neg_log_loss' else results['mean_%s_%s' % (sample, scorer)]\n",
    "        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n",
    "        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n",
    "                        sample_score_mean + sample_score_std,\n",
    "                        alpha=0.1 if sample == 'test' else 0, color=color)\n",
    "        ax.plot(X_axis, sample_score_mean, style, color=color,\n",
    "                alpha=1 if sample == 'test' else 0.7,\n",
    "                label=\"%s (%s)\" % (scorer, sample))\n",
    "\n",
    "    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n",
    "    best_score = -results['mean_test_%s' % scorer][best_index] if scoring[scorer]=='neg_log_loss' else results['mean_test_%s' % scorer][best_index]\n",
    "        \n",
    "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
    "    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n",
    "            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n",
    "\n",
    "    # Annotate the best score for that scorer\n",
    "    ax.annotate(\"%0.2f\" % best_score,\n",
    "                (X_axis[best_index], best_score + 0.005))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looping through multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    NuSVC(probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    MLPClassifier(hidden_layer_sizes=(100,100,100),batch_size=10,max_iter=200),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='multinomial')]\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*max(map(lambda x: len(x.__class__.__name__), classifiers)))\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "    train_predictions = clf.predict_proba(X_test)\n",
    "    ll = log_loss(y_test, train_predictions)\n",
    "    print(\"Log Loss: {:.4f}\".format(ll))\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "print(\"=\"*max(map(lambda x: len(x.__class__.__name__), classifiers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Barplots display\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
    "\n",
    "plt.xlabel('Accuracy %')\n",
    "plt.title('Classifier Accuracy')\n",
    "plt.show()\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Log Loss', y='Classifier', data=log, color=\"g\")\n",
    "\n",
    "plt.xlabel('Log Loss')\n",
    "plt.title('Classifier Log Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "favorite_clf = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
    "favorite_clf.fit(train, labels)\n",
    "test_predictions = favorite_clf.predict_proba(test)\n",
    "\n",
    "# Format DataFrame\n",
    "submission = pd.DataFrame(test_predictions, columns=classes)\n",
    "submission.insert(0, 'id', test_ids)\n",
    "submission.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a model using Pickle and Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(model, filename)\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. https://www.linkedin.com/pulse/approaching-almost-any-machine-learning-problem-abhishek-thakur\n",
    "2. https://github.com/abhishekkrthakur/greedyFeatureSelection\n",
    "3. https://github.com/vsmolyakov/experiments_with_python/blob/master/chp01/ensemble_methods.ipynb\n",
    "4. https://www.kaggle.com/mnassrib/titanic-logistic-regression-with-python\n",
    "5. https://www.kaggle.com/mnassrib/twelve-classifiers-for-standardized-leaf-dataset#Stratified-Train/Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
