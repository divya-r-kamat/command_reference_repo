{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "import re\n",
    "\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    ''' Takes file as input and return a dataframe '''\n",
    "    df=pd.read_table(path,sep=';')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial view of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intial_analysis(dataframe):\n",
    "       \n",
    "    print('\\033[1m' + \"\\nDisplay the shape (columns and rows) of the dataset:\" +'\\033[0m' )\n",
    "    print(\"\\tRows : {}\\n\\tColumns : {}\".format(dataframe.shape[0],dataframe.shape[1]))\n",
    "    \n",
    "    print('\\033[1m' + \"\\nInformation about the dataset:\" +'\\033[0m')\n",
    "    dataframe.info()\n",
    "    \n",
    "    print('\\033[1m' + \"\\nDetails on Numerical and Categorical features within dataset:\\n\" + '\\033[0m')\n",
    "    #list the number of Numerical Features in our dataset.\n",
    "    numerical_feature_columns = list(df._get_numeric_data().columns)\n",
    "    print(\"Numeric Columns:\",numerical_feature_columns)\n",
    "    \n",
    "    #let's find out the number of Categorical Features in our dataset.\n",
    "    categorical_feature_columns = list(set(df.columns) - set(df._get_numeric_data().columns))\n",
    "    print(\"Categorical Columns:\",categorical_feature_columns)\n",
    "    \n",
    "\n",
    "    print('\\033[1m' + \"\\nPrint any null values within dataset:\\n\" + '\\033[0m')\n",
    "                \n",
    "    labels = []\n",
    "    values = []\n",
    "    for col in dataframe.columns:\n",
    "        labels.append(col)\n",
    "        values.append(dataframe[col].isnull().sum())\n",
    "        if values[-1]!=0:\n",
    "            print(col, values[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_features(df):\n",
    "    #let's find out the number of numerical Features in our dataset.\n",
    "    numerical_feature_columns = list(df._get_numeric_data().columns)\n",
    "    return numerical_feature_columns\n",
    "\n",
    "def categorical_features(df):\n",
    "    #let's find out the number of Categorical Features in our dataset.\n",
    "    categorical_feature_columns = list(set(df.columns) - set(df._get_numeric_data().columns))\n",
    "    return categorical_feature_columns\n",
    "\n",
    "def categorical_labels(df,categorical_feature_columns):\n",
    "    for var in categorical_feature_columns:\n",
    "        print(var, 'contains :', len(df[var].unique()), ' labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missing_values(df):\n",
    "    #check null values \n",
    "    df_na = (df.isnull().sum() / len(df)) * 100\n",
    "    df_na = df_na.drop(df_na[df_na == 0].index).sort_values(ascending=False)[:30]\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :df_na})\n",
    "    \n",
    "    if (df_na.shape[0] != 0):\n",
    "        f, ax = plt.subplots(figsize=(8, 6))\n",
    "        plt.xticks(rotation='90')\n",
    "        sns.barplot(x=df_na.index, y=df_na)\n",
    "        plt.xlabel('Features', fontsize=15)\n",
    "        plt.ylabel('Percent of missing values', fontsize=15)\n",
    "        plt.title('Percent missing data by feature', fontsize=15)\n",
    "        \n",
    "    return missing_data.head(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_plots(df):\n",
    "    num_cols = list(df._get_numeric_data().columns)\n",
    "    for i in range(0,len(num_cols),2):\n",
    "        if len(num_cols) > i+1:\n",
    "            plt.figure(figsize=(8,2))\n",
    "            plt.subplot(121)\n",
    "            sns.distplot(df[num_cols[i]], hist=True, kde=True)\n",
    "            plt.subplot(122)            \n",
    "            sns.distplot(df[num_cols[i+1]], hist=True, kde=True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            sns.distplot(df[num_cols[i]], hist=True, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def box_plot(df):\n",
    "    num_cols = list(df._get_numeric_data().columns)\n",
    "    for i in range(0,len(num_cols),2):\n",
    "        if len(num_cols) > i+1:\n",
    "            plt.figure(figsize=(10,4))\n",
    "            plt.subplot(121)\n",
    "            sns.boxplot(x=df[num_cols[i]],orient='v')\n",
    "            plt.subplot(122)            \n",
    "            sns.boxplot(x=df[num_cols[i+1]],orient='v')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        else:\n",
    "            sns.boxplot(x=df[num_cols[i]],orient='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_residuals(y_test,y_pred,name=\"Residual Plot\"):\n",
    "    residuals = y_test - y_pred\n",
    "    plt.scatter(y_test,residuals)\n",
    "    plt.hlines(y=0, xmin=0, xmax=10)\n",
    "    plt.title(name)\n",
    "    plt.ylabel('Residual')\n",
    "    plt.xlabel('Fitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_outlier(df_in, col_name):\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "    q3 = df_in[col_name].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    fence_low  = q1-1.5*iqr\n",
    "    fence_high = q3+1.5*iqr\n",
    "    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardizing numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize(df,columns):\n",
    "    stand_scale= StandardScaler()\n",
    "    column_transform = columns\n",
    "    df.loc[:, column_transform] = stand_scale.fit_transform(df.loc[:, column_transform])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split for validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Let us break the X and y dataframes into training set and test set. For this we will use\n",
    "#Sklearn package's data splitting function which is based on random function\n",
    "# Split X and y into training and test set in 80:20 ratio\n",
    "\n",
    "def split_dataset(df):\n",
    "    X=df.iloc[:,:-1]\n",
    "    y=df.iloc[:,-1]\n",
    "    \n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=1,test_size=0.30)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "def cross_validation_regressor(model,x_train,y_train):\n",
    "    kf = KFold(n_splits=10, random_state=7)\n",
    "    score = cross_val_score(model,x_train,y_train,cv=kf)\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "def linear_regression(X_train,y_train,X_test, y_test):\n",
    "    regressor = LinearRegression()\n",
    "    model = regressor.fit(X_train,y_train)    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    val = cross_validation_regressor(regressor,X_train,y_train)\n",
    "    adj_r_squared = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)- X_test.shape[1]- 1)\n",
    "    stats = pd.DataFrame({'cross_validation':val,'rmse':rmse,'mse':mse,'mae':mae,'r2':r2,'adj_r_squared':adj_r_squared},index=['name'])\n",
    "    return model,y_pred,stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def lasso(x_train,x_test,y_train,y_test,alpha):\n",
    "    lass = Lasso(alpha=alpha,random_state=7,normalize=True)\n",
    "    model = lass.fit(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    r2=model.score(x_test,y_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    val = cross_validation_regressor(lass,x_train,y_train)\n",
    "    adj_r_squared = 1 - (1-r2)*(len(y_test)-1)/(len(y_test)- x_test.shape[1]- 1)\n",
    "    stats = pd.DataFrame({'cross_validation':val,\n",
    "                         'rmse':rmse,'mse':mse,'mae':mae,'r2':(model.score(x_test,y_test)),'adj_r_squared':adj_r_squared},index=['name'])\n",
    "    return model,y_pred,stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
